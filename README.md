# 🏁 regatta

**Algorithmic Game Theory and Strategic Interaction — from fundamentals to frontier methods.**

`regatta` is a personal learning and research repository for building and understanding computational approaches to game theory.  
It draws inspiration from DeepMind’s work on **PSRO**, **AlphaRank**, and **DeepNash**, as well as OpenSpiel and classical theoretical foundations.

---

### 🧠 Goals
- Recreate **foundational game-theoretic algorithms** from scratch.
- Implement **modern learning and regret-minimization methods**.
- Reproduce **frontier results** from DeepMind, OpenAI, and academia.
- Provide an **experimental sandbox** for exploring equilibria and population dynamics.

---

### 📂 Structure
```
regatta/
├── core/          # Foundational algorithms and data structures
├── learning/      # Learning and regret-minimization algorithms
├── experiments/   # Jupyter experiments and reproductions
└── docs/          # Notes, references, and reproductions
```

---

### 🚀 Getting Started

```bash
git clone https://github.com/acb-code/regatta.git
cd regatta
pip install -e .
```

For development:
```bash
pip install -e ".[dev]"
```

---

### 📚 References
- **Shoham & Leyton-Brown (2008)** – *Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations*
- **Balduzzi et al. (2018)** – *PSRO: Policy-Space Response Oracles*
- **Omidshafiei et al. (2019)** – *AlphaRank: Multi-agent Evaluation via Evolutionary Dynamics*
- **Perolat et al. (2022)** – *Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning*

---

### ⚓ License
MIT © Alexander Braafladt
